package com.noodleofdeath.pastaparser.io.lexer;

import java.util.List;

import com.noodleofdeath.pastaparser.io.TokenStream;
import com.noodleofdeath.pastaparser.io.token.TextToken;
import com.noodleofdeath.pastaparser.io.token.Token;
import com.noodleofdeath.pastaparser.model.grammar.event.listener.GrammarEventGenerator;
import com.noodleofdeath.pastaparser.model.grammar.event.listener.LexerListener;
import com.noodleofdeath.pastaparser.model.grammar.Grammar;
import com.noodleofdeath.pastaparser.model.grammar.rule.GrammarRule;
import com.noodleofdeath.pastaparser.model.graph.tree.syntaxtree.LexerSyntaxTree;

/**
 * Specifications for a lexer.
 * 
 * @param <R> raw type used by the tokens generated by this lexer.
 * @param <T> type of token generated by this lexer.
 */
public interface Lexer<R, T extends Token<R>> extends GrammarEventGenerator<LexerListener<R, T>> {

	/**
	 * 
	 */
	public static final int OptionInverted = 1 << 0;

	/** @return */
	public abstract Grammar grammar();

	/** @param Grammar */
	public abstract void setGrammar(Grammar grammar);

	/** @return */
	public abstract List<T> unmatchedAtoms();

	/** @return */
	public abstract boolean addUnmatchedAtom(T atom);

	/**
	 * @param characterStream
	 * @return
	 */
	public default TokenStream<String, TextToken> tokenize(CharSequence characterStream) {
		return tokenize(characterStream, 0);
	}

	/**
	 * @param characterStream
	 * @param offset
	 * @return
	 */
	public abstract TokenStream<String, TextToken> tokenize(CharSequence characterStream, int offset);

	/**
	 * @param characterStream
	 * @param lexerRule
	 */
	public default LexerSyntaxTree<R, T> tokenize(CharSequence characterStream, GrammarRule lexerRule) {
		return tokenize(characterStream, lexerRule, 0, null);
	}

	/**
	 * @param characterStream
	 * @param lexerRule
	 * @param offset
	 */
	public default LexerSyntaxTree<R, T> tokenize(CharSequence characterStream, GrammarRule lexerRule, int offset) {
		return tokenize(characterStream, lexerRule, offset, null);
	}

	/**
	 * @param characterStream
	 * @param lexerRule
	 * @param offset
	 * @param syntaxTree
	 */
	public abstract LexerSyntaxTree<R, T> tokenize(CharSequence characterStream, GrammarRule lexerRule, int offset,
			LexerSyntaxTree<R, T> syntaxTree);

}
